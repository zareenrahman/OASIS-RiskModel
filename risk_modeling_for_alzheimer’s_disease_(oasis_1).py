# -*- coding: utf-8 -*-
"""Risk Modeling for Alzheimer’s Disease (OASIS-1)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mzfur164Bc6H053admnYU6OqInUUjM2i

# Explainable Risk Modeling for Alzheimer’s Disease (OASIS-1)

**Goal**
1) Train an interpretable model to predict dementia status (CDR>0 vs CDR=0)
2) Avoid leakage caused by MR1/MR2 duplicate scans using subject-level splits
3) Report robust performance via GroupKFold cross-validation
4) Add uncertainty via bootstrapping (risk distribution per subject)
5) Demonstrate a simple “digital-twin” what-if intervention (MMSE change)
6) Provide interpretable effects (odds ratios) with human-readable feature names

**Approach**  
We use a regularized logistic regression model with:
- strict separation of training and evaluation data,
- uncertainty estimation via bootstrap resampling,
- and simple virtual interventions (e.g., cognitive score changes) to simulate digital twin behavior.

**Why this matters**  
Rather than treating models as black boxes, this workflow emphasizes interpretability, robustness, and clinical relevance, aligning with modern perspectives on explainable AI and digital twins in healthcare.

**Dataset**  
OASIS-1: Cross-sectional MRI-derived clinical and demographic data (n ≈ 430 subjects).
"""

# ============================================================
# 0) Setup: imports + config
# ============================================================

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import GroupKFold, cross_val_predict
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    roc_auc_score, accuracy_score,
    classification_report, confusion_matrix,
    roc_curve
)
from sklearn.base import clone

# ============================================================
# 1) Download + load OASIS-1 clinical table
# ============================================================

URL = "https://sites.wustl.edu/oasisbrains/files/2024/04/oasis_cross-sectional-5708aa0a98d82080.xlsx"
OUT = "oasis1_clinical.xlsx"

if not os.path.exists(OUT):
    !wget -O {OUT} --tries=10 --waitretry=2 --read-timeout=20 --timeout=20 "{URL}"

df = pd.read_excel(OUT)
print("Raw shape:", df.shape)
df.head()

"""OASIS contains some subjects with **repeated sessions (MR1/MR2)**. To prevent optimistic bias, we group-split by subject, ensuring no subject appears in both train/test folds."""

# ============================================================
# 2) Define target + subject groups (prevents MR1/MR2 leakage)
# ============================================================

df = df.copy()

# Target: dementia spectrum vs control
df["target"] = (df["CDR"] > 0).astype(int)

# Subject ID = part before "_MR1" or "_MR2"
df["subject_id"] = df["ID"].astype(str).str.replace(r"_MR\d+$", "", regex=True)

# Features we will use (interpretable + clinically plausible)
features_num = ["Age", "Educ", "MMSE"]
features_cat = ["M/F"]
features_all = features_num + features_cat

# Keep rows with needed fields
df_model = df.dropna(subset=["CDR", "target", "subject_id"] + features_all).copy()

print("Modeling rows:", len(df_model))
print("Unique subjects:", df_model["subject_id"].nunique())
print("Class balance:\n", df_model["target"].value_counts())

# ============================================================
# 3) Build interpretable ML pipeline (impute + encode + scale + LR)
# ============================================================

numeric_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler()),
])

categorical_transformer = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(drop="if_binary", handle_unknown="ignore")),
])

preprocess = ColumnTransformer([
    ("num", numeric_transformer, features_num),
    ("cat", categorical_transformer, features_cat),
])

pipeline = Pipeline([
    ("preprocess", preprocess),
    ("lr", LogisticRegression(
        class_weight="balanced",
        solver="liblinear",
        max_iter=2000,
        random_state=42
    ))
])

"""**Confusion Matrix (Model Performance): **

- This confusion matrix summarizes 5-fold subject-level cross-validated performance.
- The model correctly identifies most cognitively normal and dementia cases, with a balanced error profile.
- **GroupKFold** ensures that repeated MRI sessions from the same individual never appear in both training and test folds.
"""

# ============================================================
# 4A) Cross-validated performance estimation (GroupKFold, no leakage)
# ============================================================

X_all = df_model[features_all]
y_all = df_model["target"]
groups = df_model["subject_id"]

cv = GroupKFold(n_splits=5)

y_prob_cv = cross_val_predict(
    pipeline,
    X_all, y_all,
    cv=cv,
    groups=groups,
    method="predict_proba"
)[:, 1]

y_pred_cv = (y_prob_cv >= 0.5).astype(int)

auc = roc_auc_score(y_all, y_prob_cv)
acc = accuracy_score(y_all, y_pred_cv)

print(f"5-Fold GroupKFold AUC: {auc:.3f}")
print(f"5-Fold GroupKFold Accuracy: {acc:.3f}\n")

print("Confusion matrix:")
cm = confusion_matrix(y_all, y_pred_cv)
print(cm)

print("\nClassification report:")
print(classification_report(y_all, y_pred_cv, target_names=["Control (CDR=0)", "Dementia (CDR>0)"]))

# --- ROC curve ---
fpr, tpr, _ = roc_curve(y_all, y_prob_cv)
plt.figure()
plt.plot(fpr, tpr)
plt.plot([0, 1], [0, 1], linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title(f"ROC Curve (GroupKFold CV) | AUC={auc:.3f}")
plt.show()

# --- Confusion matrix heatmap (simple) ---
plt.figure()
plt.imshow(cm, cmap="Blues", vmin=0)
plt.title("Confusion Matrix (GroupKFold CV)")
plt.xticks([0, 1], ["Control", "Dementia"])
plt.yticks([0, 1], ["Control", "Dementia"])

for (i, j), v in np.ndenumerate(cm):
    plt.text(j, i, str(v), ha="center", va="center", color="black")

plt.xlabel("Predicted")
plt.ylabel("True")
plt.colorbar()
plt.show()

"""Beyond discrimination metrics (AUC), clinical deployment requires
**well-calibrated probabilities** and demonstrable **decision-level benefit**.
"""

# ============================================================
# 4B) Decision Curve Analysis (Clinical utility / net benefit)
# ============================================================

# Calibration curve

from sklearn.calibration import calibration_curve

prob_true, prob_pred = calibration_curve(y_all, y_prob_cv, n_bins=10, strategy="quantile")

plt.figure()
plt.plot(prob_pred, prob_true, marker="o")
plt.plot([0,1],[0,1], linestyle="--")
plt.xlabel("Predicted risk")
plt.ylabel("Observed dementia rate")
plt.title("Calibration (GroupKFold CV predictions)")
plt.show()

# Decision curve (Net Benefit)

def net_benefit(y_true, y_prob, threshold):
    y_pred = (y_prob >= threshold).astype(int)
    tp = ((y_pred == 1) & (y_true == 1)).sum()
    fp = ((y_pred == 1) & (y_true == 0)).sum()
    n = len(y_true)
    return (tp / n) - (fp / n) * (threshold / (1 - threshold))

thresholds = np.linspace(0.05, 0.95, 19)
nb_model = [net_benefit(y_all.values, y_prob_cv, t) for t in thresholds]

# treat-all baseline
prevalence = y_all.mean()
nb_all = [prevalence - (1 - prevalence) * (t / (1 - t)) for t in thresholds]
nb_none = [0 for _ in thresholds]

plt.figure()
plt.plot(thresholds, nb_model, label="Model")
plt.plot(thresholds, nb_all, linestyle="--", label="Treat all")
plt.plot(thresholds, nb_none, linestyle="--", label="Treat none")
plt.xlabel("Risk threshold")
plt.ylabel("Net benefit")
plt.title("Decision Curve Analysis (clinical utility)")
plt.legend()
plt.show()

"""Bootstrap Uncertainty (Patient-level Risk):

- Instead of a single risk score, we estimate a distribution of dementia probabilities using bootstrap resampling.
- This captures model uncertainty and reflects how confident the model is for an individual patient.
- It shows that this is **uncertainty-aware ML**, which is **not overconfident** and **clinically responsible modeling**.
"""

# ============================================================
# 5) Bootstrap-based uncertainty estimation (subject-level bootstrap)
# ============================================================


def bootstrap_predict_proba_subjectwise(pipeline, X, y, groups, X_eval, n_boot=200, seed=42):
    rng = np.random.default_rng(seed)
    subjects = pd.Series(groups).astype(str).values
    unique_subj = np.unique(subjects)

    probs = []
    for _ in range(n_boot):
        sampled_subj = rng.choice(unique_subj, size=len(unique_subj), replace=True)

        # build bootstrap row indices with multiplicity
        boot_indices = []
        for s in sampled_subj:
            idx_s = np.where(subjects == s)[0]
            boot_indices.extend(idx_s.tolist())

        Xb = X.iloc[boot_indices]
        yb = y.iloc[boot_indices]

        m = clone(pipeline)
        m.fit(Xb, yb)
        probs.append(m.predict_proba(X_eval)[:, 1])

    return np.vstack(probs)

# Evaluate uncertainty on a small evaluation set (first 30 rows)
X_eval = X_all.iloc[:30].copy()
boot_probs = bootstrap_predict_proba_subjectwise(
    pipeline, X_all, y_all, groups, X_eval, n_boot=200, seed=42
)

print("boot_probs shape:", boot_probs.shape)  # (n_boot, n_eval)

# Plot uncertainty for one patient
i = 0
mean_prob = boot_probs[:, i].mean()

plt.figure()
plt.hist(boot_probs[:, i], bins=30, density=True)
plt.axvline(
    mean_prob,
    color="#D55E00",
    linestyle="--",
    linewidth=2,
    label="Mean predicted risk"
)
plt.xlabel("Predicted dementia probability")
plt.ylabel("Density")
plt.title("Bootstrap Uncertainty (one subject)")
plt.legend()
plt.tight_layout()
plt.show()

"""Virtual Intervention (Digital Twin-style What-if):
- We simulate a ***hypothetical decline in MMSE score by 2 points and recompute dementia risk. ***
- The rightward shift in the distribution demonstrates how cognitive decline increases** predicted risk**, illustrating a simple digital-twin-style intervention.
"""

# ============================================================
# 6) Virtual intervention: simulate MMSE decrease (what-if)
# ============================================================

# Virtual intervention input: simulate MMSE decrease (what-if)

X_eval_intervene = X_eval.copy()
X_eval_intervene["MMSE"] = X_eval_intervene["MMSE"] - 2

# Virtual intervention effect: re-estimate risk distribution

boot_probs_intervene = bootstrap_predict_proba_subjectwise(
    pipeline, X_all, y_all, groups, X_eval_intervene, n_boot=200, seed=42
)

# Plot before vs after for one patient
plt.figure()
plt.hist(boot_probs[:, i], bins=30, alpha=0.6, label="Original", density=True)
plt.hist(boot_probs_intervene[:, i], bins=30, alpha=0.6,
         label="MMSE −2", density=True)
plt.xlabel("Predicted dementia probability")
plt.ylabel("Density")
plt.title("Virtual Intervention (Digital Twin-style What-if)")
plt.legend()
plt.show()

# Summarize mean risk shift
delta = boot_probs_intervene.mean(axis=0) - boot_probs.mean(axis=0)
pd.DataFrame({"mean_risk_shift_MMSE_minus2": delta}).head(10)

"""Model Interpretability (Log-odds coefficients):

- Logistic regression coefficients are shown on the log-odds scale.
- Lower MMSE scores and higher age are associated with increased dementia risk, aligning with clinical knowledge.
"""

# ============================================================
# 7) Interpretability: coefficients -> odds ratios
# ============================================================

# Step 7A) Fit and create odds-ratio table
pipeline.fit(X_all, y_all)

preprocess = pipeline.named_steps["preprocess"]
raw_feature_names = preprocess.get_feature_names_out()

FEATURE_NAME_MAP = {
    "num__Age": "Age (years)",
    "num__Educ": "Years of education",
    "num__MMSE": "MMSE score",
    "cat__M/F_M": "Sex: Male (vs Female)",
}

pretty_feature_names = [FEATURE_NAME_MAP.get(n, n) for n in raw_feature_names]

coefs = pipeline.named_steps["lr"].coef_.ravel()

print("len(features):", len(pretty_feature_names), "| len(coefs):", len(coefs))

coef_table = pd.DataFrame({
    "feature": pretty_feature_names,
    "coef": coefs,
    "odds_ratio": np.exp(coefs),
}).sort_values("coef", key=np.abs, ascending=False)

from IPython.display import display
display(coef_table)

# Step 7B) Plot top coefficients
top_k = 10
top = coef_table.head(top_k)

colors = ["#D55E00" if c > 0 else "#0072B2" for c in top["coef"]]

import matplotlib.pyplot as plt
plt.figure(figsize=(7, 4))
plt.barh(top["feature"], top["coef"], color=colors)
plt.axvline(0, color="black", linestyle="--", linewidth=1)
plt.xlabel("Log-odds coefficient")
plt.title("Most influential predictors of dementia risk")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

from sklearn.metrics import RocCurveDisplay

RocCurveDisplay.from_predictions(y_true=y_all, y_pred=y_prob_cv)
plt.title("ROC Curve (GroupKFold CV)")
plt.show()